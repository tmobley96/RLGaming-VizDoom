{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68526e56-d693-4876-aea9-a8075c8f5327",
   "metadata": {},
   "source": [
    "# 1. Getting VizDoom Up and Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c764084-f50c-4452-8809-0323f18c638e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vizdoom in c:\\users\\thaddeus\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\thaddeus\\anaconda3\\lib\\site-packages (from vizdoom) (1.24.3)\n",
      "Requirement already satisfied: gymnasium>=0.28.0 in c:\\users\\thaddeus\\anaconda3\\lib\\site-packages (from vizdoom) (0.29.1)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\thaddeus\\anaconda3\\lib\\site-packages (from vizdoom) (2.5.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\thaddeus\\anaconda3\\lib\\site-packages (from gymnasium>=0.28.0->vizdoom) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\thaddeus\\anaconda3\\lib\\site-packages (from gymnasium>=0.28.0->vizdoom) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\thaddeus\\anaconda3\\lib\\site-packages (from gymnasium>=0.28.0->vizdoom) (0.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce221aa7-6c59-40e6-a252-d57cb7b93cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ViZDoom' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!cd github & git clone https://github.com/Farama-Foundation/ViZDoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed19d376-933d-42db-a03e-82da5623288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import vizdoom for game env\n",
    "from vizdoom import *\n",
    "#Import random for action sampling\n",
    "import random\n",
    "#Import time for sleeping b/w frames\n",
    "import time\n",
    "#Import numpy for identity matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce88723-5f6e-434b-9c7d-7b162f998e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup game\n",
    "game = DoomGame()\n",
    "game.load_config('github/VizDoom/scenarios/basic.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4b01f9-4816-497c-a8f4-c120d9333af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the set of actions we can take in the environment\n",
    "actions = np.identity(3, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e241e59-1a6e-41b4-a473-f0caa8040f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: 99.0\n",
      "Result: 91.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n",
      "Reward: -9.0\n",
      "Reward: -4.0\n",
      "Result: -375.0\n",
      "Reward: -4.0\n",
      "Reward: -4.0\n"
     ]
    },
    {
     "ename": "ViZDoomUnexpectedExitException",
     "evalue": "Controlled ViZDoom instance exited unexpectedly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mViZDoomUnexpectedExitException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m info \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mgame_variables\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#Take an action\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#Print reward\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReward:\u001b[39m\u001b[38;5;124m'\u001b[39m, reward)\n",
      "\u001b[1;31mViZDoomUnexpectedExitException\u001b[0m: Controlled ViZDoom instance exited unexpectedly."
     ]
    }
   ],
   "source": [
    "#Loop thorugh episodes\n",
    "episodes = 10\n",
    "for episode in range(episodes):\n",
    "    #Create a new episode or game\n",
    "    game.new_episode()\n",
    "    #Checking hte game isn't finish\n",
    "    while not game.is_episode_finished():\n",
    "        #Get the game state\n",
    "        state = game.get_state()\n",
    "        #Get the game image\n",
    "        img = state.screen_buffer\n",
    "        #Get the game variables - ammo\n",
    "        info = state.game_variables\n",
    "        #Take an action\n",
    "        reward = game.make_action(random.choice(actions),4)\n",
    "        #Print reward\n",
    "        print('Reward:', reward)\n",
    "        time.sleep(0.02)\n",
    "    print('Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf8d76-61ab-4a15-a53c-da4ded33bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8438f2-92e5-44cc-9db7-695a52e6fe74",
   "metadata": {},
   "source": [
    "# 2. Converting it to a Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba2bf1-4be2-4033-b417-92f0f8f280b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a8ff8c-4fd2-4889-959c-91ddbd9b4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import environment base class from OpenAI Gym\n",
    "import gymnasium as gym\n",
    "\n",
    "#Import gym spaces\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "#Import opencv\n",
    "import cv2\n",
    "#Import vizdoom for game env\n",
    "from vizdoom import *\n",
    "#Import random for action sampling\n",
    "import random\n",
    "#Import time for sleeping b/w frames\n",
    "import time\n",
    "#Import numpy for identity matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "817742f2-7b69-4b03-b63d-be107484cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Vizdoom OpenAI Gym Environment\n",
    "class VizDoomGym(gym.Env):\n",
    "    #Function that is called when we start the env\n",
    "    def __init__(self, render=False):\n",
    "        #Inherit from Env\n",
    "        super().__init__()\n",
    "        #Setup the game\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config('github/VizDoom/scenarios/basic.cfg')\n",
    "\n",
    "        #Render frame Logic\n",
    "        if render == False:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "       \n",
    "        #Start the game\n",
    "        self.game.init() \n",
    "       \n",
    "        #Create the action space and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100,160,1), dtype=np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "\n",
    "    #This is how we take a step in the env    \n",
    "    def step(self, action):\n",
    "        #Specify action and take step\n",
    "        actions = np.identity(3, dtype=np.uint8)\n",
    "        reward = self.game.make_action(actions[action], 4)\n",
    "\n",
    "        #Get all the other stuff we need to reutrn\n",
    "        if self.game.get_state():\n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.grayscale(state)\n",
    "            ammo = self.game.get_state().game_variables[0]\n",
    "            info = ammo\n",
    "        else:\n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0\n",
    "\n",
    "        info = {\"info\":info}\n",
    "        done = self.game.is_episode_finished()\n",
    "        truncated = False\n",
    "\n",
    "        return state, reward, done, truncated, info\n",
    "        \n",
    "    #Define how to render the game or environment\n",
    "    def render():\n",
    "        pass\n",
    "    #What happen when we start a new game\n",
    "    def reset(self, seed=None):\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        ammo = self.game.get_state().game_variables[0]\n",
    "        info = {\"ammo\":ammo}\n",
    "        return self.grayscale(state), info\n",
    "        \n",
    "    #Grayscale the game frame and resize it\n",
    "    def grayscale(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100,160,1))\n",
    "        return state\n",
    "        \n",
    "    #Call to close down the game\n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5145e1c-0124-4d3f-8f59-1d56a365a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75a6f7-a571-4c49-bd25-0763761b9ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992824e2-d917-4ef8-9bb7-16b0136c1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33e3388-012e-459c-9223-58bad4ea03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70e1476d-5ae4-480c-9530-26b61636688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Environment checker\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07386df-cf79-4d91-9bf3-a9077e27eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526ccfb-1ccb-468a-9826-6fd748bc383f",
   "metadata": {},
   "source": [
    "# 3. View State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651d755-f043-40a7-9e66-a153bafd5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e758daa6-38ca-4b18-a3ae-ddc49d227531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38578a54-efd6-4e89-a979-7fa1dcca69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(state, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874f9da-2f99-4c0c-a69b-b30c5ee7a200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca1151-994f-4050-9641-dc6b8a9f50a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5926df6f-fef1-465a-87a7-fa1359347c02",
   "metadata": {},
   "source": [
    "# 4. Setup Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28a2c3-7f2f-4368-a9d6-28660a2f4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec7cdb-1803-4012-92b0-f7761e784ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0646e1-1587-45f0-ab4a-f57bac0d82ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7501828-b484-4ddb-a186-b22e4a328d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import os for file nav\n",
    "import os\n",
    "#Import callback class from sb3\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349af317-5a04-4491-80de-68cf2e89955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e642c6a-51cb-41a2-9580-35ce1157aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_basic'\n",
    "LOG_DIR = './logs/log_basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc73a347-6f57-4a01-844a-2d2d0460e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f163974-da4b-418b-840c-71dd66695a0d",
   "metadata": {},
   "source": [
    "# 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8412032b-c826-49d3-b73a-0db39d9769f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import PPO for training\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75712c01-b31d-4f02-8165-16350e507872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non rendered environment\n",
    "env = VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa8dc9fa-27a5-4d9a-bbd8-ff930839aa94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01752088-5a52-4874-87ac-e3de421fcd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24c62634-63f9-4f12-9a99-f5dd35ce4fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_basic\\PPO_6\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -66.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 43       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.6        |\n",
      "|    ep_rew_mean          | -50.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008570114 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.000102   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 26.1       |\n",
      "|    ep_rew_mean          | -42.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 40         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01269076 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.0908     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.38e+03   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00203   |\n",
      "|    value_loss           | 3.45e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.6        |\n",
      "|    ep_rew_mean          | -42.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012557166 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.00387     |\n",
      "|    value_loss           | 2.86e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.8        |\n",
      "|    ep_rew_mean          | -30.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058767356 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.00344     |\n",
      "|    value_loss           | 3.18e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20          |\n",
      "|    ep_rew_mean          | -11.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048354834 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.0068      |\n",
      "|    value_loss           | 3.21e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19          |\n",
      "|    ep_rew_mean          | -10.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020423442 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.00653     |\n",
      "|    value_loss           | 3.65e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.3        |\n",
      "|    ep_rew_mean          | -14.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023466047 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.0049      |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.4        |\n",
      "|    ep_rew_mean          | 3.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011496557 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.968      |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.00383     |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 18.7       |\n",
      "|    ep_rew_mean          | -5.17      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 40         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 510        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01327414 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.936     |\n",
      "|    explained_variance   | 0.769      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.08e+03   |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | 0.00703    |\n",
      "|    value_loss           | 2.8e+03    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.5        |\n",
      "|    ep_rew_mean          | 34.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010060292 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.964      |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.000303   |\n",
      "|    value_loss           | 3.43e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 13.1       |\n",
      "|    ep_rew_mean          | 34         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 617        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01986621 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.895     |\n",
      "|    explained_variance   | 0.729      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.73e+03   |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.00846    |\n",
      "|    value_loss           | 3.58e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.24        |\n",
      "|    ep_rew_mean          | 57.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017863296 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.00454     |\n",
      "|    value_loss           | 4.02e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.7        |\n",
      "|    ep_rew_mean          | 16.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036831222 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 524         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.0285      |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.1       |\n",
      "|    ep_rew_mean          | 49.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 777        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05436369 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.8       |\n",
      "|    explained_variance   | 0.602      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 638        |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | 0.00783    |\n",
      "|    value_loss           | 1.63e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.14        |\n",
      "|    ep_rew_mean          | 74.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 833         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055627517 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.76       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 877         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.0172      |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.87        |\n",
      "|    ep_rew_mean          | 75.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 888         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037660517 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 376         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    value_loss           | 1.12e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.43        |\n",
      "|    ep_rew_mean          | 73.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 944         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040153578 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.00791     |\n",
      "|    value_loss           | 365         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.81       |\n",
      "|    ep_rew_mean          | 76.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 1000       |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10981404 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.655     |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 281        |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | 0.0438     |\n",
      "|    value_loss           | 602        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.59        |\n",
      "|    ep_rew_mean          | 77.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 1056        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032695476 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    value_loss           | 408         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.38      |\n",
      "|    ep_rew_mean          | 78.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 1113      |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0562303 |\n",
      "|    clip_fraction        | 0.24      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.449    |\n",
      "|    explained_variance   | 0.51      |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 82.7      |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | 0.0254    |\n",
      "|    value_loss           | 218       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.32        |\n",
      "|    ep_rew_mean          | 83.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1172        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049802504 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.391      |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 291         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.0332      |\n",
      "|    value_loss           | 353         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.58      |\n",
      "|    ep_rew_mean          | 82.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 38        |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 1230      |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0352101 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.368    |\n",
      "|    explained_variance   | 0.388     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 161       |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | 0.0197    |\n",
      "|    value_loss           | 268       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.96        |\n",
      "|    ep_rew_mean          | 86.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1288        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040381044 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 39.8        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00372     |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.35       |\n",
      "|    ep_rew_mean          | 84.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 1342       |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03296288 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.4       |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 69.7       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | 0.0517     |\n",
      "|    value_loss           | 84.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.27        |\n",
      "|    ep_rew_mean          | 85.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1396        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018997919 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 40.7        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.0167      |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.79        |\n",
      "|    ep_rew_mean          | 83.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 1451        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026656684 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.0222      |\n",
      "|    value_loss           | 90.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.23        |\n",
      "|    ep_rew_mean          | 85.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1506        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023244098 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.0236      |\n",
      "|    value_loss           | 68.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.87       |\n",
      "|    ep_rew_mean          | 87.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 1566       |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05550106 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.236     |\n",
      "|    explained_variance   | 0.635      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 62.9       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | 0.0128     |\n",
      "|    value_loss           | 92.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.19        |\n",
      "|    ep_rew_mean          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1622        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054690935 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.195      |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.00947     |\n",
      "|    value_loss           | 97          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 86          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1680        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044533685 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.185      |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.0112      |\n",
      "|    value_loss           | 97.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.18       |\n",
      "|    ep_rew_mean          | 85.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 1735       |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06984986 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.174     |\n",
      "|    explained_variance   | 0.577      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 64.4       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | 0.0155     |\n",
      "|    value_loss           | 111        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.25      |\n",
      "|    ep_rew_mean          | 85.3      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 1794      |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0303387 |\n",
      "|    clip_fraction        | 0.0845    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.162    |\n",
      "|    explained_variance   | 0.648     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 18.7      |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | 0.0251    |\n",
      "|    value_loss           | 76.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.92        |\n",
      "|    ep_rew_mean          | 82.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1851        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039366655 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.162      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.0191      |\n",
      "|    value_loss           | 66          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.41       |\n",
      "|    ep_rew_mean          | 84.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 1907       |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04089248 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.178     |\n",
      "|    explained_variance   | 0.551      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 61.2       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | 0.0833     |\n",
      "|    value_loss           | 104        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.04        |\n",
      "|    ep_rew_mean          | 86.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1964        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023604658 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.155      |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 81.4        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.0159      |\n",
      "|    value_loss           | 89.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.31       |\n",
      "|    ep_rew_mean          | 85.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 2022       |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03359897 |\n",
      "|    clip_fraction        | 0.0747     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.164     |\n",
      "|    explained_variance   | 0.712      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 7.75       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.0162     |\n",
      "|    value_loss           | 53.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.87        |\n",
      "|    ep_rew_mean          | 87.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 2079        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015184486 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.142      |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.00809     |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.13        |\n",
      "|    ep_rew_mean          | 86.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 2137        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050878648 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.13       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.0151      |\n",
      "|    value_loss           | 69.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.66       |\n",
      "|    ep_rew_mean          | 88.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 2196       |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01979671 |\n",
      "|    clip_fraction        | 0.0625     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.13      |\n",
      "|    explained_variance   | 0.687      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 26.1       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | 0.0117     |\n",
      "|    value_loss           | 55.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.87       |\n",
      "|    ep_rew_mean          | 87.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 2255       |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02346595 |\n",
      "|    clip_fraction        | 0.082      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 103        |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.00728    |\n",
      "|    value_loss           | 90.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.8        |\n",
      "|    ep_rew_mean          | 87.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 2314       |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16123669 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | 0.79       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 6.82       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | 0.0504     |\n",
      "|    value_loss           | 33.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.25        |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 2373        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019889036 |\n",
      "|    clip_fraction        | 0.0889      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.106      |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.0209      |\n",
      "|    value_loss           | 77.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.89        |\n",
      "|    ep_rew_mean          | 87.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 2431        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035523366 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.101      |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 50.9        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.0162      |\n",
      "|    value_loss           | 69.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.95        |\n",
      "|    ep_rew_mean          | 87          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 2492        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015315095 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.1        |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.0204      |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.69        |\n",
      "|    ep_rew_mean          | 87.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 2553        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029510465 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0886     |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.01        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00881     |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.89        |\n",
      "|    ep_rew_mean          | 87.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 2610        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017508028 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.113      |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.0133      |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.59        |\n",
      "|    ep_rew_mean          | 88.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 2669        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026291609 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.016       |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.97        |\n",
      "|    ep_rew_mean          | 87          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 2729        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018971294 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.1        |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.021       |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x22786cbe800>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f325b-734c-4772-a67d-3604ea01b63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b56e44-cf2b-4a41-b7de-30bfc6a760aa",
   "metadata": {},
   "source": [
    "# 6. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4281a02f-64a1-4016-b875-5e873b3add48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import eval policy to test agent\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc9668-19fa-45e1-9a5d-8bd205944f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a10db05-ff39-4f1d-b865-884a66b72215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload model from disc\n",
    "model = PPO.load('./train/train_basic/best_model_120000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f206cd1-8f7a-485d-9d19-63577a759eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create rendered environment\n",
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fd29a44-a7bb-427a-b39e-b62a5acacb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thaddeus\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Evaluate mean reward for 10 games\n",
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d7d3ed5-2dc8-491e-959e-6248ec1ed5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.37"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0de7c348-264d-4192-8dde-c65b835b289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[55],\n",
      "        [50],\n",
      "        [59],\n",
      "        ...,\n",
      "        [57],\n",
      "        [57],\n",
      "        [66]],\n",
      "\n",
      "       [[68],\n",
      "        [65],\n",
      "        [65],\n",
      "        ...,\n",
      "        [56],\n",
      "        [67],\n",
      "        [72]],\n",
      "\n",
      "       [[49],\n",
      "        [79],\n",
      "        [66],\n",
      "        ...,\n",
      "        [79],\n",
      "        [51],\n",
      "        [29]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[75],\n",
      "        [63],\n",
      "        [62],\n",
      "        ...,\n",
      "        [44],\n",
      "        [71],\n",
      "        [60]],\n",
      "\n",
      "       [[15],\n",
      "        [48],\n",
      "        [47],\n",
      "        ...,\n",
      "        [49],\n",
      "        [69],\n",
      "        [47]],\n",
      "\n",
      "       [[22],\n",
      "        [14],\n",
      "        [26],\n",
      "        ...,\n",
      "        [57],\n",
      "        [37],\n",
      "        [39]]], dtype=uint8), {'ammo': 50.0})\n"
     ]
    }
   ],
   "source": [
    "print(env.reset())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18239b40-530a-422d-addf-f6ce6dedd1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "Item 0 type: <class 'numpy.ndarray'>, shape: (100, 160, 1)\n",
      "Item 1 type: <class 'dict'>, shape: N/A\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "print(type(obs))\n",
    "if isinstance(obs, tuple):\n",
    "    for i, item in enumerate(obs):\n",
    "        print(f\"Item {i} type: {type(item)}, shape: {getattr(item, 'shape', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"Observation shape: {obs.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37e9477e-7093-4d9e-bec4-67a18d917059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 95.0 is 0\n",
      "Total Reward for episode 67.0 is 1\n",
      "Total Reward for episode 71.0 is 2\n",
      "Total Reward for episode 83.0 is 3\n",
      "Total Reward for episode 95.0 is 4\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        time.sleep(0.05)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(total_reward, episode))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3fb57-2b79-4879-ba7a-6da41a1281bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
